{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "### Table showing reads and index relative to file name\n",
    "\n",
    "| read1 | read2 | index1 | index2|\n",
    "|-------|-------|--------|-------|\n",
    "|1294_S1_L008_R1_001.fastq.gz| 1294_S1_L008_R4_001.fastq.gz|1294_S1_L008_R2_001.fastq.gz|1294_S1_L008_R3_001.fastq.gz|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Script shown below to create tables that were then plotted in R to create distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#make sure to change add import gzip, file, change gzip, change output file name\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "###Set up function to convert scores to phred scores###\n",
    "def convert_phred(letter):\n",
    "    \"\"\"Converts a single character into a phred score based on Illumina 1.8+Phred+33\"\"\"\n",
    "    ASCII = ord(letter) -33\n",
    "    return(ASCII)\n",
    "    \n",
    "###Create a numpy array to contain all scores for each pos###\n",
    "all_qscores_array = np.zeros((101),dtype=float)             \n",
    "#now populate array for first position\n",
    "#print(all_qscores_array)\n",
    "\n",
    "\n",
    "#file = \"/projects/bgmp/shared/2017_sequencing/1294_S1_L008_R1_001.fastq.gz\"\n",
    "#file = \"/projects/bgmp/shared/2017_sequencing/1294_S1_L008_R2_001.fastq.gz\"\n",
    "#file = \"/projects/bgmp/shared/2017_sequencing/1294_S1_L008_R3_001.fastq.gz\"\n",
    "file = \"/projects/bgmp/shared/2017_sequencing/1294_S1_L008_R4_001.fastq.gz\"\n",
    "\n",
    "#file2 = \"/projects/bgmp/jlee33/demulti_dir/table_R1\"\n",
    "#file2 = \"/projects/bgmp/jlee33/demulti_dir/table_R2\"\n",
    "#file2 = \"/projects/bgmp/jlee33/demulti_dir/table_R3\"\n",
    "file2 = \"/projects/bgmp/jlee33/demulti_dir/table_R4\"\n",
    "\n",
    "LN = 0\n",
    "#with open(file, \"r\") as fh, open(file2, \"w\") as out_fh:\n",
    "with gzip.open(file, \"rt\") as fh, open(file2, \"w\") as out_fh:\n",
    "    i = 0\n",
    "    for line in fh:\n",
    "        i+=1\n",
    "        line  = line.strip(\"\\n\")\n",
    "        if i%4==0:\n",
    "            #print(line)\n",
    "            #start a counter for how many sequences have processed(aka no. reads)\n",
    "            pos = 0    #letter position on that given line\n",
    "            #continue for the length of the line aka all things on lines\n",
    "            for pos in range(len(line)):\n",
    "                scores = convert_phred(line[pos]) #converts to character to phred score\n",
    "                #print(pos, scores)\n",
    "                #ADD THINGS TO ARRAY\n",
    "                all_qscores_array[pos]+=scores\n",
    "                \n",
    "    #create and fill mean_scores\n",
    "    mean_scores = np.zeros((101),dtype=float)\n",
    "    \n",
    "    #numpy.array/___ means divide each index by ___\n",
    "    mean_scores = all_qscores_array/(i/4)\n",
    "    \n",
    "   # print(mean_scores)\n",
    "    out_fh.write(\"# Base Pair\\tMean Quality Score\\n\")\n",
    "    pos = 0\n",
    "    for pos in range(len(mean_scores)):\n",
    "        #output of .write can only print strings so convert int varaibles\n",
    "        out_fh.write(str(pos) + \"\\t\" + str(mean_scores[pos]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See pdf in repo \n",
    "for per base call distribution of quality scores of read 1, read 2, index 1, index2\n",
    "\n",
    "\n",
    "### What is a good quality score cut off for index reads and pairs to utilize for sample identification and downstream analysis, respectively?\n",
    "\n",
    "This is a subjective cutoff. The standard quality cutoff is 30 because this contains 99.99% of data. Furthermore as a general rule of thumb, it is best to visualize the data first to see general trends. From this, pick a threshold value that occurs when there is a substantial dip in average quality score. For instance, the average quality score gets worse as the read progresses, so pick a quality score value that is reached at a steep decline on the curve.\n",
    "\n",
    "Based on the distributions of my two reads (R1 and R4), the quality score cutoff will be:\n",
    "    \n",
    "    qual sc cutoff = 30 (scores 30 and higher will be kept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many indexes have Undetermined (N) base calls? (Utilize your command line\n",
    "tool knowledge. Submit the command you used. CHALLENGE: use a one-line\n",
    "command)\n",
    "\n",
    "##### Script shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code produces two files that contain only the lines that contain N in seq\n",
    "####Index 1####\n",
    "zcat /projects/bgmp/shared/2017_sequencing/1294_S1_L008_R2_001.fastq.gz | grep -A1 \"^@\" | grep -v \"^--\" | grep -v \"^@\" | grep \"N\" | wc -l \n",
    "\n",
    "####Index 2#### \n",
    "zcat /projects/bgmp/shared/2017_sequencing/1294_S1_L008_R3_001.fastq.gz | grep -A1 \"^@\" | grep -v \"^--\" | grep -v \"^@\" | grep \"N\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then counted number of lines which is number of indexes with N\n",
    "\n",
    "    wc -l /projects/bgmp/jlee33/demulti_dir/N_index1\n",
    "\n",
    "    output = 3976613 N_index1\n",
    "\n",
    "then counted number of lines which is number of indexes with N\n",
    "wc -l /projects/bgmp/jlee33/demulti_dir/N_index2\n",
    "\n",
    "    output = 3328051 N_index2\n",
    "    \n",
    "then add numbers together\n",
    "\n",
    "    Total is: 7304664"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "Write a strategy for writing an algorithm for de-multiplexing files and reporting indexhopping. That is, given four files (2 with biological reads, 2 with index reads) and known indexes, sort reads by index, outputting one forward file and one reverse file per index, plus a pair of files for unknown indexes. Additionally, your algorithm should report the number of properly matched indexes (per index) and the level of index hopping observed. You should not write any code for this portion of the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outline\n",
    "\n",
    "Problem: Illumina output includes a mixture of several barcodes (24 different samples with 24 different barcodes) and need to separate barcodes out for downstream applications (i.e. analysis)\n",
    "\n",
    "Goal: Demultiplex data so each sample (aka index) are moved into files separate from other indexes. \n",
    "\n",
    "Output for Goal 1: Sort further so that each index has fastq output files == 1) forward reads 2) reverse reads 3) low quality reads 4) reads with one or more unknown sequences\n",
    "\n",
    "Goal 2: Analysis of level of index swapping and undertermined pairs before and after quality filetering of index reads\n",
    "\n",
    "Output for Goal2: output number of properly matched indexes (per index) and the level of index hopping observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a file that contains barcodes (tab deliniated)\n",
    "    #so column 1 has short and column two has barcode\n",
    "        #B1    GTAGCGTA\n",
    "        #A5    CGATCGAT\n",
    "        #etc for all barcodes\n",
    "#create dictionary that has all 24 expected barcoes\n",
    "    #index_dict that has column1 as key and barcode as value of above file\n",
    "\n",
    "#create comp_base_dict that contains A or T or G or C as key and the value is the complimentary base of key\n",
    "comp_base_dict = {}\n",
    "\n",
    "#create variables to refer to each file as F (forward read), I1 (index 1), I2 (index2), R (reverse read)\n",
    "F = \"test_1294_S1_L008_R1_001.fastq\"\n",
    "I1 = \"test_1294_S1_L008_R2_001.fastq\"\n",
    "I2 = \"test_1294_S1_L008_R3_001.fastq\"\n",
    "R = \"test_1294_S1_L008_R4_001.fastq\"\n",
    "\n",
    "\n",
    "#create function to read the forward index to get the reverse complimentary barcode\n",
    "def convert_to_reverse_index:\n",
    "    '''takes forward index sequence and outputs the reverse complimentary sequence (aka other barcode)'''\n",
    "    with open(I1, \"r\") as in_fh:\n",
    "        #rename each lines as header, seq, plus, qual\n",
    "        while True:\n",
    "            header equals in_hf.readline().strip()\n",
    "            if not header:\n",
    "                break   #tells to end when reach last line in file\n",
    "            seq equals in_fh.readline().strip()\n",
    "            plus equals in_fh.readline().strip()\n",
    "            qual equals in_fh.readline().strip()\n",
    "            \n",
    "            if seq in comp_base_dict #validates that barcode is one of the 24 we expected\n",
    "                look up each nucleotide in I1 as a key in comp_base_dict and print value aka the complimantery base\n",
    "                then reverse order of printed out seq (aka the reverse complimentary barcode)\n",
    "                save this string as reverse_comp_index   \n",
    "            else statement for if index doesn't match any of the 24 expected index\n",
    "                print(\"index found that shouldn't be here\")\n",
    "    return reverse_comp_index\n",
    "  \n",
    "#Create convert_phred function\n",
    "def convert_phred(letter):\n",
    "    \"\"\"Converts a single character into a phred score based on Illumina 1.8+Phred+33\"\"\"\n",
    "    ASCII = ord(letter) -33\n",
    "    return(ASCII)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create output forward and reverse for each read that is correct. \n",
    "#then two more (one for forward and one for reverse)\n",
    "    #each of those have 1) index hop 2) low qual 3)N\n",
    "\n",
    "def filter_reads ():\n",
    "    '''filters out reads with unknown sequences (have Ns) and low quality reads (<37 phred score) and index hopping. Makes new file of reads with no index hopping. Returns total_correct_indexed, total_incorrect_indexed, total_low_quality, total_with_N'''\n",
    "    with open the files F, I1, I2, and R as read\n",
    "    with open to create new output files as write (unacceptable_forward_reads.fastq and unacceptable_reverse_reads.fastq) along with acceptable_forward_reads and acceptable_reverse_reads\n",
    "    with open to create new output file as write (index_hop)\n",
    "        while True:\n",
    "            #tells program to read fastq files 4 lines at a time (header, seq, plus, qual) for ALL input files\n",
    "            header = in_fh.readline().strip()\n",
    "            if not header:\n",
    "                break   #tells to end when reach last line in file\n",
    "            seq = in_fh.readline().strip()\n",
    "            plus = in_fh.readline().strip()\n",
    "            qual = in_fh.readline().strip()\n",
    "\n",
    "            #create counters of correct and incorrectly indexed samples\n",
    "                #correct means index from forward/reverse are the same\n",
    "            total_correct_indexed = 0\n",
    "            total_index_hop = 0\n",
    "            total_low_quality = 0\n",
    "            total_with_N = 0\n",
    "    \n",
    "    ###Step 1: get rid of reads with low quality or unknown sequences###\n",
    "            #convert ASCII to phred using convert_phred and variable qual\n",
    "            #name this value as variable \"score\"\n",
    "            score = convert_phred(letter)\n",
    "\n",
    "            #if/else statement for looking at sequences with N\n",
    "            #if N is present then add read info to unknown_reads file\n",
    "            if \"n\" or \"N\" in qual of index1 fastq file or index2 fastq file:\n",
    "                #perform the follwoing write commands to write out info contained in index1 and forward read (F)\n",
    "                unacceptable_forward_reads.write(header) \n",
    "                unacceptable_forward_reads.write(seq)\n",
    "                unacceptable_forward_reads.write(plus)\n",
    "                unacceptable_forward_reads.write(qual)\n",
    "                #perform the follwing write commands to write out info contained in index2 and reverse read (R)\n",
    "                unacceptable_reverse_reads.write(header)\n",
    "                unacceptable_reverse_reads.write(seq)\n",
    "                unacceptable_reverse_reads.write(plus)\n",
    "                unacceptable_reverse_reads.write(qual)\n",
    "                #add to total N counter\n",
    "                total_with_N+=1\n",
    "            \n",
    "            #if no N (all nucleotides are determined) then continue to \n",
    "            #step that considers if qual scores are above threshold\n",
    "            else:\n",
    "                qual_thres == 30 #create variable \"qual_thres\" that is a subjective number that\n",
    "                #quality scores less than this will be not used\n",
    "                \n",
    "                #if statement: score < #qual_thres then write to file \"unacceptable_forward_reads and unnacetalbe_reverse_reads\"\n",
    "                if score < qual_thres for seq of any of the input files (read1, index1, read2, index2):\n",
    "                    #perform the follwing write commands to write out info contained in index1 and forward read (F)\n",
    "                    unaccept_forward.write(header)\n",
    "                    unaccept_forward.write(seq)\n",
    "                    unaccept_forward.write(plus)\n",
    "                    unaccept_forward.write(qual)\n",
    "                    #perform the follwing write commands to write out info contained in index2 and reverse read (R) \n",
    "                    unaccept_reverse.write(header)\n",
    "                    unaccept_reverse.write(seq)\n",
    "                    unaccept_reverse.write(plus)\n",
    "                    unaccept_reverse.write(qual)\n",
    "                    #add to counter\n",
    "                    total_low_quality+=1\n",
    "\n",
    "                    #else: score is = or > \"qual thres\" then add to forward or reverse file\n",
    "                    else:\n",
    "                    ###Step 2: determine if index swapping occured###\n",
    "                        #if not then means index from somewhere else appeared\n",
    "                        now looking at index2 fastq(I2)\n",
    "                        if seq not in index_dict:\n",
    "                            print(\"Index not on list is found\")\n",
    "                            break\n",
    "                        else seq in index_dict:\n",
    "                            continue\n",
    "                \n",
    "                    #compare index on forward/reverse read to see if \n",
    "                    #they are reverse complimentary\n",
    "\n",
    "                        created_index = #function\n",
    "\n",
    "                        #compare created_index to index from index2 file \n",
    "                        if seq of index2 fastq file == convert_reverse_index(of index1 fastq file)\n",
    "                            #perform the follwing write commands to write out info contained in index2 and forward read (F)\n",
    "                            acceptable_forward_reads.write(header)\n",
    "                            acceptable_forward_reads.write(seq)\n",
    "                            acceptable_forward_reads.write(plus)\n",
    "                            acceptable_forward_reads.write(qual)\n",
    "                            #perform the follwing write commands to write out info contained in index2 and reverse read (R)\n",
    "                            acceptable_reverse_reads.write(header)\n",
    "                            acceptable_reverse_reads.write(seq)\n",
    "                            acceptable_reverse_reads.write(plus)\n",
    "                            acceptable_reverse_reads.write(qual)\n",
    "                            #add to counter\n",
    "                            total_correct_indexed+=1\n",
    "                        else: #when indexes are not reverse complimentary (aka index hopping occured)\n",
    "                            #perform the follwing write commands to write out info contained in index 1, index2, forward read (F) and reverse read (R)\n",
    "                            index_hop.write(header)\n",
    "                            index_hop.write(seq)\n",
    "                            index_hop.write(plus)     \n",
    "                            index_hop.write(qual)\n",
    "                            total_index_hop+=1\n",
    "    ###program then loops back and repeats for all lines in file\n",
    "    return (total_correct_indexed, total_index_hop, total_low_quality, total_with_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit tests \n",
    "using test examples for individual functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert_phred function\n",
    "def convert_phred(letter):\n",
    "    \"\"\"Converts a single character into a phred score based on Illumina 1.8+Phred+33\"\"\"\n",
    "    ASCII = ord(letter) -33\n",
    "    return(ASCII)\n",
    "\n",
    "assert convert_phred(\"A\") == 32\n",
    "assert convert_phred(\"B\") == 33\n",
    "assert convert_phred(\"T\") == 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create dictionary of known 24 indexed libraries\n",
    "    #fill with the specific barcodes in that flow cell\n",
    "index_dict = {\"B1\":\"GTAGCGTA\", \"A5\": \"CGATCGAT\", \"C1\": \"GATCAAGG\", \"B9\": \"AACAGCGA\", \"C9\": \"TAGCCATG\", \"C3\": \"CGGTAATC\", \"B3\": \"CTCTGGAT\", \"C4\": \"TACCGGAT\", \"A11\": \"CTAGCTCA\", \"C7\": \"CACTTCAC\", \"B2\": \"GCTACTCT\", \"A1\" : \"ACGATCAG\"}\n",
    "\n",
    "assert index_dict[\"B1\"] == \"GTAGCGTA\"\n",
    "assert index_dict[\"A5\"] == \"CGATCGAT\"\n",
    "assert index_dict[\"C1\"] == \"GATCAAGG\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
